<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-modules/vla/chapter1" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 1: The Confluence of Vision and Language in Robotics | Physical AI &amp; Humanoid Robotics Textbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter1"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="ur"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 1: The Confluence of Vision and Language in Robotics | Physical AI &amp; Humanoid Robotics Textbook"><meta data-rh="true" name="description" content="1.1 What are Vision-Language Models (VLMs)?"><meta data-rh="true" property="og:description" content="1.1 What are Vision-Language Models (VLMs)?"><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics-Textbook/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter1"><link data-rh="true" rel="alternate" href="https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter1" hreflang="en"><link data-rh="true" rel="alternate" href="https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/ur/docs/modules/vla/chapter1" hreflang="ur"><link data-rh="true" rel="alternate" href="https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter1" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Module 4: VLA","item":"https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/"},{"@type":"ListItem","position":2,"name":"Chapter 1: The Confluence of Vision and Language in Robotics","item":"https://Muntaha-Noor.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter1"}]}</script><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics-Textbook/assets/css/styles.bf06faf4.css">
<script src="/Physical-AI-Humanoid-Robotics-Textbook/assets/js/runtime~main.50707f48.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics-Textbook/assets/js/main.e8c32b14.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Physical-AI-Humanoid-Robotics-Textbook/img/lllogo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics-Textbook/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics-Textbook/img/lllogo.png" alt="Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics-Textbook/img/lllogo.png" alt="Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/intro">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter1" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/Physical-AI-Humanoid-Robotics-Textbook/ur/docs/modules/vla/chapter1" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ur">اردو</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/intro"><span title="Course Overview: Physical AI &amp; Humanoid Robotics" class="linkLabel_WmDU">Course Overview: Physical AI &amp; Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/course-fundamentals"><span title="Course Fundamentals" class="categoryLinkLabel_W154">Course Fundamentals</span></a><button aria-label="Expand sidebar category &#x27;Course Fundamentals&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/advanced-topics"><span title="Advanced Topics" class="categoryLinkLabel_W154">Advanced Topics</span></a><button aria-label="Expand sidebar category &#x27;Advanced Topics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/ros2/"><span title="modules" class="categoryLinkLabel_W154">modules</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/ros2/"><span title="Module 1: ROS 2" class="categoryLinkLabel_W154">Module 1: ROS 2</span></a><button aria-label="Expand sidebar category &#x27;Module 1: ROS 2&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/simulation/"><span title="Module 2: Simulation" class="categoryLinkLabel_W154">Module 2: Simulation</span></a><button aria-label="Expand sidebar category &#x27;Module 2: Simulation&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/isaac-ai/"><span title="Module 3: Isaac AI" class="categoryLinkLabel_W154">Module 3: Isaac AI</span></a><button aria-label="Expand sidebar category &#x27;Module 3: Isaac AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/"><span title="Module 4: VLA" class="categoryLinkLabel_W154">Module 4: VLA</span></a><button aria-label="Collapse sidebar category &#x27;Module 4: VLA&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter1"><span title="Chapter 1: The Confluence of Vision and Language in Robotics" class="linkLabel_WmDU">Chapter 1: The Confluence of Vision and Language in Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter2"><span title="Chapter 2: Building a Voice-Controlled Robot with ROS 2 and Whisper" class="linkLabel_WmDU">Chapter 2: Building a Voice-Controlled Robot with ROS 2 and Whisper</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter3"><span title="Chapter 3: Advanced Task Planning with Large Language Models" class="linkLabel_WmDU">Chapter 3: Advanced Task Planning with Large Language Models</span></a></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics-Textbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">modules</span></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/"><span>Module 4: VLA</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Chapter 1: The Confluence of Vision and Language in Robotics</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 1: The Confluence of Vision and Language in Robotics</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="11-what-are-vision-language-models-vlms">1.1 What are Vision-Language Models (VLMs)?<a href="#11-what-are-vision-language-models-vlms" class="hash-link" aria-label="Direct link to 1.1 What are Vision-Language Models (VLMs)?" title="Direct link to 1.1 What are Vision-Language Models (VLMs)?" translate="no">​</a></h2>
<p>For decades, the fields of computer vision and natural language processing (NLP) evolved largely in parallel. Computer vision focused on understanding pixels, while NLP focused on understanding text. Vision-Language Models (VLMs) represent a paradigm shift, merging these two disciplines to create AI models that can understand and reason about the world in a more holistic, human-like way.</p>
<p>A VLM is a multimodal AI model that can process information from both images (or video) and text simultaneously. This allows it to perform tasks that are impossible for a unimodal model.</p>
<p><strong>Core Capabilities of VLMs:</strong></p>
<ul>
<li class=""><strong>Visual Question Answering (VQA):</strong> Given an image and a natural language question (e.g., &quot;How many apples are on the table?&quot;), the model provides a textual answer.</li>
<li class=""><strong>Image Captioning:</strong> The model generates a concise, human-like description of an image. (e.g., &quot;A brown dog catching a red frisbee in a grassy park.&quot;).</li>
<li class=""><strong>Grounded Language Understanding (Visual Grounding):</strong> The model connects words or phrases in a text to specific objects or regions within an image. If you say, &quot;the bottle on the left,&quot; the model can identify which pixels correspond to that specific bottle. This is crucial for robotics.</li>
<li class=""><strong>Text-to-Image Retrieval:</strong> Given a textual description, the model can search a database of images and find the ones that best match the description.</li>
</ul>
<p>For a robot, these capabilities mean it can understand instructions that refer to objects in its environment, like &quot;pick up the blue cup&quot; instead of requiring precise coordinates.</p>
<hr>
<p>*Placeholder for a diagram: &quot;The VLM Architecture.&quot; This diagram should show two main branches:</p>
<ol>
<li class=""><strong>Vision Encoder:</strong> An input image is fed into a vision backbone (e.g., a Vision Transformer - ViT) which outputs a set of image features (embeddings).</li>
<li class=""><strong>Language Encoder:</strong> An input text prompt is fed into a language model (e.g., a Transformer decoder like GPT) which outputs text embeddings.</li>
<li class=""><strong>Fusion Layer:</strong> These two sets of embeddings are then fused together through a &quot;cross-attention&quot; mechanism, allowing the model to learn the relationships between visual concepts and words.</li>
<li class=""><strong>Output Head:</strong> The fused representation is then passed to a final layer that generates the desired output (e.g., an answer, a caption, or a bounding box).</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="12-the-engine-of-understanding-large-language-models-llms">1.2 The Engine of Understanding: Large Language Models (LLMs)<a href="#12-the-engine-of-understanding-large-language-models-llms" class="hash-link" aria-label="Direct link to 1.2 The Engine of Understanding: Large Language Models (LLMs)" title="Direct link to 1.2 The Engine of Understanding: Large Language Models (LLMs)" translate="no">​</a></h2>
<p>The recent, dramatic improvements in VLMs are largely thanks to the power of Large Language Models (LLMs). LLMs are neural networks, typically based on the Transformer architecture, that have been trained on truly massive amounts of text data.</p>
<p><strong>How LLMs Changed the Game:</strong></p>
<ol>
<li class=""><strong>Emergent Abilities:</strong> When trained at a massive scale, LLMs develop &quot;emergent abilities&quot;—skills that they were not explicitly programmed to have. These include common-sense reasoning, basic arithmetic, and the ability to understand context and nuance in language.</li>
<li class=""><strong>The Transformer Architecture:</strong> The core innovation behind most modern LLMs is the Transformer, which uses a mechanism called &quot;self-attention.&quot; Self-attention allows the model to weigh the importance of different words in the input text relative to each other, giving it a sophisticated understanding of grammar and syntax.</li>
<li class=""><strong>Pre-training and Fine-tuning:</strong>
<ul>
<li class=""><strong>Pre-training:</strong> An LLM is first &quot;pre-trained&quot; on a vast, general corpus of text (like a significant portion of the internet). The objective is simple: predict the next word in a sentence. By doing this billions of times, the model learns an incredible amount about language and the world.</li>
<li class=""><strong>Fine-tuning:</strong> After pre-training, the general model can be &quot;fine-tuned&quot; on a smaller, curated dataset for a specific task. This adapts the model&#x27;s general knowledge to a specialized domain, like medical text analysis or, in our case, robotics commands.</li>
</ul>
</li>
</ol>
<p>When this powerful language understanding is fused with a vision system, the resulting VLM can connect the rich, abstract knowledge learned from text to the concrete, visual information from its sensors.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="13-the-openai-api-your-gateway-to-powerful-ai-models">1.3 The OpenAI API: Your Gateway to Powerful AI Models<a href="#13-the-openai-api-your-gateway-to-powerful-ai-models" class="hash-link" aria-label="Direct link to 1.3 The OpenAI API: Your Gateway to Powerful AI Models" title="Direct link to 1.3 The OpenAI API: Your Gateway to Powerful AI Models" translate="no">​</a></h2>
<p>For this course, we will leverage pre-trained models from OpenAI, which are accessible through a simple and well-documented API. This allows us to stand on the shoulders of giants and integrate state-of-the-art AI into our projects without needing to train these massive models ourselves.</p>
<ul>
<li class=""><strong>GPT (Generative Pre-trained Transformer):</strong> A family of LLMs. We will primarily use the chat-based models (like <code>gpt-3.5-turbo</code> and <code>gpt-4</code>) which are optimized for dialogue and instruction-following. These models will be the &quot;brain&quot; of our robot, helping it to reason and plan.</li>
<li class=""><strong>Whisper:</strong> A state-of-the-art automatic speech recognition (ASR) model. It is trained on a huge dataset of multilingual audio and can transcribe spoken language into text with remarkable accuracy, even in noisy conditions. Whisper will be the &quot;ears&quot; of our robot.</li>
</ul>
<p><strong>Getting Your API Key:</strong></p>
<ol>
<li class=""><strong>Create an OpenAI Account:</strong> Go to the <a href="https://platform.openai.com/" target="_blank" rel="noopener noreferrer" class="">OpenAI platform website</a> and sign up.</li>
<li class=""><strong>Set Up Billing:</strong> You will need to add a payment method to your account to use the API. OpenAI provides a small amount of free credits for new users, but usage beyond that is paid.</li>
<li class=""><strong>Generate an API Key:</strong> Navigate to the &quot;API Keys&quot; section in your account dashboard. Click &quot;Create new secret key.&quot; <strong>Important:</strong> Copy this key and save it somewhere safe. You will not be able to see it again. <strong>Never commit your API key to a public code repository.</strong></li>
</ol>
<p><strong>Setting Up Your Environment:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Install the OpenAI Python library</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># It is highly recommended to set your API key as an environment variable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Add this line to your ~/.bashrc or ~/.zshrc file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export OPENAI_API_KEY=&#x27;YOUR_API_KEY_HERE&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Then, source the file to apply the changes (e.g., source ~/.bashrc)</span><br></span></code></pre></div></div>
<p><strong>Example: A Robust API Call to GPT-4</strong></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># The library will automatically pick up the OPENAI_API_KEY environment variable</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># openai.api_key = os.getenv(&quot;OPENAI_API_KEY&quot;) # This is done implicitly now</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">try</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> openai</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;gpt-4&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Or &quot;gpt-3.5-turbo&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        messages</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;role&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;system&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;You are a helpful assistant.&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;role&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;user&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;What is the relationship between Isaac Newton and Gottfried Leibniz?&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        max_tokens</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">150</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Accessing the response content correctly</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    message_content </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> response</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">message</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">content</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">message_content</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">except</span><span class="token plain"> openai</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">APIError </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> e</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;An OpenAI API error occurred: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">except</span><span class="token plain"> Exception </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> e</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;An unexpected error occurred: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p><em>This script shows the modern, recommended way to interact with OpenAI&#x27;s chat models, including basic error handling.</em></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="14-a-ros-2-bridge-for-vlm-integration">1.4 A ROS 2 Bridge for VLM Integration<a href="#14-a-ros-2-bridge-for-vlm-integration" class="hash-link" aria-label="Direct link to 1.4 A ROS 2 Bridge for VLM Integration" title="Direct link to 1.4 A ROS 2 Bridge for VLM Integration" translate="no">​</a></h2>
<p>To cleanly integrate these cloud-based AI models into our local robotics system, we&#x27;ll create a dedicated ROS 2 node. This node will act as a service provider, accepting requests from other ROS 2 nodes, calling the OpenAI API, and returning the result. This architectural pattern is much cleaner than having every node make its own API calls.</p>
<p><strong>Creating the ROS 2 Package:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Navigate to your ROS 2 workspace&#x27;s src directory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd ~/ros2_ws/src</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create a new package for our VLM services</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ros2 pkg create --build-type ament_python vlm_services --dependencies rclpy std_msgs</span><br></span></code></pre></div></div>
<p><strong>Creating a Basic ROS 2 Service Node:</strong></p>
<p>Create a new Python file <code>openai_service_node.py</code> in the <code>vlm_services/vlm_services</code> directory. We&#x27;ll start with a simple service that takes a string and returns a string.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># First, let&#x27;s define a custom service in our package.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Create a file named &quot;StringToString.srv&quot; in a new &quot;srv&quot; directory </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># inside the &quot;vlm_services&quot; package with the following content:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># string input</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ---</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># string output</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Then, modify package.xml and CMakeLists.txt to build the service.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># The Python node (openai_service_node.py):</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> rclpy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># We will create this custom service later</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># from vlm_services.srv import StringToString </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">OpenAIServiceNode</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Node</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;openai_service_node&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># We will uncomment this when the service is defined</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># self.srv = self.create_service(StringToString, &#x27;openai_service&#x27;, self.service_callback)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;OpenAI service node has been started.&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">service_callback</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> request</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> response</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&#x27;Received request: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">request</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation builtin">input</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># This is where we would call the OpenAI API</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># For now, we&#x27;ll just echo the input</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">output </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;OpenAI response for: &quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> request</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">input</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> response</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">main</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">args</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">init</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">args</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">args</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    openai_service_node </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> OpenAIServiceNode</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">spin</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">openai_service_node</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    openai_service_node</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">destroy_node</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shutdown</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> __name__ </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;__main__&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    main</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p><em>This code provides a robust starting point for an API service node. In the following chapters, we will build out the service definition and the API call logic.</em></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="15-summary">1.5 Summary<a href="#15-summary" class="hash-link" aria-label="Direct link to 1.5 Summary" title="Direct link to 1.5 Summary" translate="no">​</a></h2>
<p>In this chapter, you&#x27;ve taken a deep dive into the concepts behind Vision-Language Models. You learned how they represent a fusion of computer vision and NLP, driven by the power of Large Language Models. You&#x27;ve also set up your developer environment to access the state-of-the-art OpenAI API and laid the architectural foundation for integrating these powerful cloud services into your ROS 2 projects. In the next chapter, we will build on this foundation to create a voice-controlled robotics system using the Whisper API.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/spect-kit-plus/Hakathon_01/tree/main/Humanoid_Robotics/docs/modules/04-vla/01-chapter1.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Module 4: Vision-Language-Action (VLA)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/modules/vla/chapter2"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 2: Building a Voice-Controlled Robot with ROS 2 and Whisper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#11-what-are-vision-language-models-vlms" class="table-of-contents__link toc-highlight">1.1 What are Vision-Language Models (VLMs)?</a></li><li><a href="#12-the-engine-of-understanding-large-language-models-llms" class="table-of-contents__link toc-highlight">1.2 The Engine of Understanding: Large Language Models (LLMs)</a></li><li><a href="#13-the-openai-api-your-gateway-to-powerful-ai-models" class="table-of-contents__link toc-highlight">1.3 The OpenAI API: Your Gateway to Powerful AI Models</a></li><li><a href="#14-a-ros-2-bridge-for-vlm-integration" class="table-of-contents__link toc-highlight">1.4 A ROS 2 Bridge for VLM Integration</a></li><li><a href="#15-summary" class="table-of-contents__link toc-highlight">1.5 Summary</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">© 2025 Physical AI & Humanoid Robotics Textbook • Designed and developed ❤️ by Muntaha Noor</div></div></div></footer><button class="chatButton_wzwY">Chat</button></div>
</body>
</html>