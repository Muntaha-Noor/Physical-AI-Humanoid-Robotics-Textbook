# باب 3: ROS 2 انضمام اور سم ٹو ریئل ورک فلو

## 3.1 ROS 2 برج: سمیلیشن اور حقیقت کو جوڑنا

آئزک سم میں روبوٹکس کی ترقی کے لیے سب سے اہم سرعت کار اس کا روبوٹ آپریٹنگ سسٹم (ROS 2) کے ساتھ بغیر کسی رکاوٹ کے انضمام ہے۔ یہ آپ کے موجودہ ROS 2 سافٹ ویئر اسٹیک — آپ کے نیویگیشن، پرسیپشن، اور مینیپولیشن نوڈس — کو بغیر کسی ترمیم کے چلانے کی اجازت دیتا ہے، جس میں سمیلیٹر فزیکل روبوٹ اور اس کے ماحول کے لیے ایک اسٹینڈ ان کے طور پر کام کرتا ہے۔

**ROS 2 برج کیسے کام کرتا ہے:**

آئزک سم کا ROS 2 برج سمیلیشن ماحول اور ROS 2 نیٹ ورک کے درمیان متحرک طور پر ایک دو طرفہ مواصلاتی چینل بناتا ہے۔ یہ آئزک سم کے اندرونی فارمیٹ اور معیاری ROS 2 پیغام کی اقسام کے درمیان ڈیٹا کا خود بخود ترجمہ کرتا ہے۔

*   **سمیلیشن سے ROS 2:** آئزک سم میں تیار کردہ سینسر ڈیٹا (کیمرہ امیجز، LiDAR اسکینز، IMU ریڈنگز) کو معیاری ROS 2 پیغامات (`sensor_msgs/Image`، `sensor_msgs/LaserScan`، وغیرہ) کے طور پر ROS 2 نیٹ ورک پر شائع کیا جاتا ہے۔
*   **ROS 2 سے سمیلیشن:** آپ کے ROS 2 نوڈس سے کمانڈز (جیسے نیویگیشن کے لیے `geometry_msgs/Twist` یا مینیپولیشن کے لیے `trajectory_msgs/JointTrajectory`) کو سبسکرائب کیا جاتا ہے اور نقلی روبوٹ کے جوڑوں اور جسموں کو کنٹرول کرنے کے لیے استعمال کیا جاتا ہے۔

***
*تفصیلی خاکہ کے لیے پلیس ہولڈر: "آئزک سم ROS 2 برج فن تعمیر۔" اس خاکہ میں ایک طرف آئزک سم ایپلی کیشن اور دوسری طرف ROS 2 نیٹ ورک کو دکھایا جانا چاہیے۔ تیروں کو ڈیٹا کے بہاؤ کو دکھانا چاہیے:
- آئزک سم میں ایک نقلی کیمرہ/LiDAR سے -> ROS 2 برج کے ذریعے -> `sensor_msgs/Image` اور `sensor_msgs/LaserScan` ٹاپکس تک۔
- ایک ROS 2 `Nav2` نوڈ سے -> ایک `geometry_msgs/Twist` پیغام شائع کرنا -> ROS 2 برج کے ذریعے -> آئزک سم میں ایک نقلی روبوٹ پر ایک `DifferentialDrive` کنٹرولر تک۔
- یہ سینسنگ اور کنٹرول دونوں کے لیے دو طرفہ ڈیٹا کے تبادلے کی وضاحت کرتا ہے۔
***

## 3.2 سمیلیشن ڈیٹا کو ROS 2 پر شائع کرنا: ایک عملی گائیڈ

آئیے آئزک سم سے ROS 2 ٹاپکس پر سینسر ڈیٹا شائع کرنے کے عمل سے گزرتے ہیں۔ ہم ایک کیمرہ اور ایک LiDAR سینسر کے لیے مثالیں فراہم کریں گے۔

**شرائط:**

1.  **ROS 2 برج کو فعال کریں:** آئزک سم میں، `Window > Extensions` پر جائیں، `omni.isaac.ros2_bridge` تلاش کریں، اور یقینی بنائیں کہ ٹوگل فعال ہے۔
2.  **اپنا ROS 2 ماحول سورس کریں:** ٹرمینل سے آئزک سم لانچ کرنے سے پہلے، یقینی بنائیں کہ آپ اپنی ROS 2 انسٹالیشن کو سورس کریں (جیسے، `source /opt/ros/humble/setup.bash`)۔ یہ یقینی بناتا ہے کہ آئزک سم ضروری ROS 2 لائبریریاں تلاش کر سکتا ہے۔

**مثال 1: کیمرا ڈیٹا شائع کرنا (RGB اور ڈیپتھ)**

یہ پائتھن اسکرپٹ پروگرام کے مطابق ایک کیمرا بناتا ہے اور اس کے RGB اور ڈیپتھ ڈیٹا کے لیے ROS 2 پبلشرز سیٹ اپ کرتا ہے۔

```python
import omni.graph.core as og
from omni.isaac.core.utils.prims import get_prim_at_path, define_prim
from omni.isaac.core_nodes.scripts.utils import set_target_prims

# فرض کریں کہ ایک روبوٹ پرائم /World/MyRobot پر موجود ہے
robot_prim_path = "/World/MyRobot/chassis_link" 

# ایک کیمرا پرائم بنائیں اور اسے روبوٹ سے منسلک کریں
camera_prim = define_prim(f"{robot_prim_path}/camera", "Camera")

# ROS 2 کیمرا ہیلپر گراف بنائیں
try:
    og.Controller.create_node(
        "/ROS_Camera",
        "omni.isaac.ros2_bridge.ROS2CameraHelper",
        "RosCameraGraph"
    )
except og.OmniGraphError as e:
    # یہ ہو سکتا ہے اگر نوڈ پہلے سے موجود ہو
    pass 

# گراف کے لیے ہدف کیمرا سیٹ کریں
set_target_prims(
    prim_path="/ROS_Camera/RosCameraGraph",
    target_prim_paths=[camera_prim.GetPath()],
    input_name="inputs:cameraPrim",
)

# ROS 2 ٹاپک کے نام اور دیگر پیرامیٹرز سیٹ کریں
og.Controller.attribute("/ROS_Camera/RosCameraGraph.inputs:topicName").set("camera/rgb")
og.Controller.attribute("/ROS_Camera/RosCameraGraph.inputs:depthTopicName").set("camera/depth")
og.Controller.attribute("/ROS_Camera/RosCameraGraph.inputs:cameraInfoTopicName").set("camera/camera_info")
og.Controller.attribute("/ROS_Camera/RosCameraGraph.inputs:frameId").set("camera_link")
og.Controller.attribute("/ROS_Camera/RosCameraGraph.inputs:type").set("camera") # 'camera', 'depth', 'rgb', 'distance_to_image_plane' ہو سکتا ہے


print("ROS 2 کیمرا پبلشرز سیٹ اپ ہو گئے ہیں۔")

# اس اسکرپٹ کو چلانے اور "Play" دبانے کے بعد، آپ ڈیٹا کا معائنہ کرنے کے لیے ROS 2 ٹولز استعمال کر سکتے ہیں:
# ros2 topic echo /camera/rgb
# ros2 run rqt_image_view rqt_image_view /camera/depth
```

**مثال 2: LiDAR ڈیٹا شائع کرنا**

```python
# فرض کریں کہ ایک LiDAR پرائم /World/MyRobot/lidar_sensor پر موجود ہے
lidar_prim_path = "/World/MyRobot/lidar_sensor"

# ROS 2 Lidar ہیلپر گراف بنائیں
try:
    og.Controller.create_node(
        "/ROS_Lidar",
        "omni.isaac.ros2_bridge.ROS2LidarScan",
        "RosLidarGraph"
    )
except og.OmniGraphError as e:
    pass

# ہدف lidar پرائم سیٹ کریں
set_target_prims(
    prim_path="/ROS_Lidar/RosLidarGraph",
    target_prim_paths=[lidar_prim_path],
    input_name="inputs:lidarPrim",
)

# ٹاپک اور frame_id سیٹ کریں
og.Controller.attribute("/ROS_Lidar/RosLidarGraph.inputs:topicName").set("laser_scan")
og.Controller.attribute("/ROS_Lidar/RosLidarGraph.inputs:frameId").set("lidar_link")

print("ROS 2 LiDAR پبلشر سیٹ اپ ہو گیا ہے۔")

# ROS 2 میں ویژولائز کرنے کے لیے:
# ros2 run rviz2 rviz2 -d $(ros2 pkg prefix isaac_ros_apriltag)/share/isaac_ros_apriltag/rviz/apriltag.rviz
# پھر /laser_scan ٹاپک کے لیے ایک LaserScan ڈسپلے شامل کریں۔
```

## 3.3 روبوٹ کنٹرول کے لیے ROS 2 ٹاپکس کو سبسکرائب کرنا

اب الٹا: اپنے ROS 2 نوڈس سے نقلی روبوٹ کو کنٹرول کرنا۔ سب سے عام استعمال کا معاملہ `/cmd_vel` کے ساتھ موبائل بیس کو کنٹرول کرنا ہے۔

**پائتھن کا استعمال کرتے ہوئے اقدامات:**

1.  **صحیح کنٹرولرز شامل کریں:** یقینی بنائیں کہ آپ کے روبوٹ کے پاس آئزک سم میں صحیح فزکس کنٹرولرز ہیں۔ کارٹر جیسے ڈیفرینشل ڈرائیو روبوٹ کے لیے، آپ کو روبوٹ کے بیس پرائم پر ایک `Articulation Root` اور ایک `Differential Drive` جزو لاگو کرنے کی ضرورت ہے۔
2.  **ایک ROS 2 سبسکرائبر نوڈ بنائیں:** آئزک سم عام ROS 2 پیغامات کو سبسکرائب کرنے کے لیے ہیلپر نوڈس فراہم کرتا ہے۔

**مثال: ایک `Twist` پیغام کے ساتھ کارٹر روبوٹ چلانا**

```python
import omni.graph.core as og
from omni.isaac.core_nodes.scripts.utils import set_target_prims

# روبوٹ پرائم کا راستہ جس میں DifferentialDrive کنٹرولر ہے
robot_prim_path = "/World/Carter"

# ایک ROS 2 سبسکرائب ٹوئسٹ گراف بنائیں
try:
    og.Controller.create_node(
        "/ROS_Control",
        "omni.isaac.ros2_bridge.ROS2SubscribeTwist",
        "RosTwistSubscriber"
    )
except og.OmniGraphError as e:
    pass

# سبسکرائبر کے لیے ہدف روبوٹ سیٹ کریں
set_target_prims(
    prim_path="/ROS_Control/RosTwistSubscriber",
    target_prim_paths=[robot_prim_path],
    input_name="inputs:targetPrim"
)

# ٹاپک کا نام سیٹ کریں
og.Controller.attribute("/ROS_Control/RosTwistSubscriber.inputs:topicName").set("cmd_vel")

print("کارٹر روبوٹ کے لیے ROS 2 ٹوئسٹ سبسکرائبر سیٹ اپ ہو گیا ہے۔")

# اب، ایک علیحدہ ROS 2 ٹرمینل سے، آپ کمانڈز شائع کر سکتے ہیں:
# 0.5 m/s پر آگے بڑھنے کے لیے:
# ros2 topic pub /cmd_vel geometry_msgs/msg/Twist "{linear: {x: 0.5, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 0.0}}"
# 0.5 rad/s پر جگہ پر مڑنے کے لیے:
# ros2 topic pub /cmd_vel geometry_msgs/msg/Twist "{linear: {x: 0.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 0.5}}"
```

## 3.4 سم ٹو ریئل ورک فلو: پکسلز سے پکی سڑک تک

آئزک سم استعمال کرنے کا حتمی مقصد مضبوط روبوٹکس سافٹ ویئر کی ترقی کو تیز کرنا ہے جو حقیقی دنیا میں کام کرتا ہے۔ یہ "سم ٹو ریئل" عمل ایک منظم ورک فلو ہے۔

**سم ٹو ریئل کے چار ستون:**

1.  **ایک اعلیٰ مخلص ڈیجیٹل ٹوئن بنائیں:** یہ بنیاد ہے۔
    *   **کائیمیٹکس:** روبوٹ ماڈل کے لنک کی لمبائی اور جوڑوں کی خصوصیات کو فزیکل روبوٹ سے بالکل مماثل ہونا چاہیے۔ ایک درست URDF یا CAD ماڈل سے درآمد کریں۔
    *   **ڈائنامکس:** کمیت، انرشیا، اور رگڑ کی خصوصیات کو حقیقی روبوٹ کے رویے سے ملنے کے لیے ٹیون کیا جانا چاہیے۔
    *   **سینسرز:** نقلی سینسرز کو صحیح طریقے سے رکھا جانا چاہیے اور ان کے پیرامیٹرز (جیسے، کیمرے کی فوکل لینتھ، LiDAR اسکین پیٹرن) کو حقیقی ہارڈویئر سے ملنا چاہیے۔
    *   **ماحول:** نقلی ماحول کو حقیقی دنیا کی تعیناتی کی جگہ کی پیچیدگی اور ظاہری شکل کو پکڑنا چاہیے۔

2.  **سمیلیشن میں تیار اور ٹیسٹ کریں:** یہ مرکزی ترقیاتی لوپ ہے۔
    *   اپنے پرسیپشن، نیویگیشن، اور مینیپولیشن الگورتھم کو تیار کرنے اور ڈی بگ کرنے کے لیے ڈیجیٹل ٹوئن کا استعمال کریں۔
    *   ٹیسٹ منظرنامے بنانے کے لیے سمیلیٹر کا فائدہ اٹھائیں جو حقیقی دنیا میں قائم کرنا مشکل، خطرناک، یا وقت طلب ہیں (جیسے، ہنگامی اسٹاپس یا بے ترتیب جگہوں پر رویوں کی جانچ کرنا)۔

3.  **"حقیقت کے فرق" کو پر کریں:** یہ سب سے مشکل مرحلہ ہے۔ "حقیقت کا فرق" سمیلیشن اور حقیقت کے درمیان ٹھیک ٹھیک فرق کا مجموعہ ہے۔
    *   **ڈومین رینڈمائزیشن (DR):** جیسا کہ پہلے زیر بحث آیا، بناوٹ، روشنی، اشیاء کی پوزیشنوں، اور یہاں تک کہ فزکس کی خصوصیات کو منظم طریقے سے بے ترتیب بنائیں۔ یہ آپ کے AI ماڈلز کو کسی کام کی ضروری خصوصیات سیکھنے پر مجبور کرتا ہے، بجائے اس کے کہ سمیلیشن کی تفصیلات کو یاد کیا جائے۔
    *   **فزکس ٹیوننگ:** سمیلیشن میں فزکس پیرامیٹرز کو ٹیون کرنے کے لیے حقیقی دنیا کا ڈیٹا استعمال کریں۔ مثال کے طور پر، آپ حقیقی سطح پر روبوٹ کے پہیوں کی رگڑ کی پیمائش کر سکتے ہیں اور اس قدر کو سمیلیٹر میں سیٹ کر سکتے ہیں۔

4.  **تعینات اور بہتر بنائیں:**
    *   ایک بار جب آپ کا سافٹ ویئر اسٹیک بے ترتیب سمیلیشنز کی ایک وسیع رینج میں مضبوطی سے کارکردگی کا مظاہرہ کر رہا ہے، تو آپ اسے فزیکل روبوٹ پر تعینات کر سکتے ہیں۔
    *   چونکہ آپ معیاری ROS 2 API استعمال کر رہے ہیں، یہ منتقلی اکثر سافٹ ویئر کے نقطہ نظر سے بغیر کسی رکاوٹ کے ہوتی ہے۔
    *   حقیقی دنیا میں روبوٹ کی کارکردگی کا مشاہدہ کریں۔ اگر آپ کو تضادات ملتے ہیں، تو اس معلومات کو اپنے ڈیجیٹل ٹوئن کو بہتر بنانے کے لیے استعمال کریں (جیسے، فزکس کو ایڈجسٹ کرکے یا زیادہ حقیقت پسندانہ بے ترتیبی شامل کرکے)، اور پھر سائیکل کو دہرائیں۔

***
*فلو چارٹ کے لیے پلیس ہولڈر: "تکراری سم ٹو ریئل لوپ۔"
1.  باکس: "ڈیجیٹل ٹوئن بنائیں/ بہتر بنائیں۔"
2.  باکس کی طرف تیر: "سمیلیشن میں تیار اور ٹیسٹ کریں (ڈومین رینڈمائزیشن کے ساتھ)۔"
3.  باکس کی طرف تیر: "فزیکل روبوٹ پر تعینات کریں۔"
4.  باکس کی طرف تیر: "تضادات کی نشاندہی کریں (حقیقی دنیا کی ناکامیاں)۔"
5.  "تضادات کی نشاندہی کریں" سے واپس "ڈیجیٹل ٹوئن بنائیں/ بہتر بنائیں" کی طرف اشارہ کرنے والا تیر، لوپ کو بند کرتا ہے۔ یہ عمل کی تکراری نوعیت پر زور دیتا ہے۔
***

## 3.5 خلاصہ

اس باب میں، آپ نے آئزک سم کو اپنے روبوٹکس سافٹ ویئر سے جوڑنے میں ROS 2 برج کے اہم کردار کے بارے میں سیکھا۔ آپ نے سینسر ڈیٹا شائع کرنے اور کنٹرول کمانڈز کو سبسکرائب کرنے کے عملی، کوڈ پر مبنی مثالیں دیکھیں۔ سب سے اہم بات یہ ہے کہ آپ کو منظم سم ٹو ریئل ورک فلو سے متعارف کرایا گیا، جو مضبوط، حقیقی دنیا کے لیے تیار روبوٹس تیار کرنے کے لیے ایک طاقتور طریقہ کار ہے۔ یہ NVIDIA آئزک سم پر ہمارے ماڈیول کا اختتام ہے۔ اگلے ماڈیول میں، ہم یہ دریافت کریں گے کہ وژن-لینگویج ماڈلز کا استعمال کرتے ہوئے اپنے روبوٹس کو دنیا کی گہری سمجھ کیسے دی جائے۔
