# باب 1: روبوٹکس میں وژن اور زبان کا سنگم

## 1.1 وژن-لینگویج ماڈلز (VLMs) کیا ہیں؟

کئی دہائیوں تک، کمپیوٹر وژن اور قدرتی زبان کی پروسیسنگ (NLP) کے شعبے زیادہ تر متوازی طور پر تیار ہوئے۔ کمپیوٹر وژن نے پکسلز کو سمجھنے پر توجہ مرکوز کی، جبکہ NLP نے متن کو سمجھنے پر توجہ مرکوز کی۔ وژن-لینگویج ماڈلز (VLMs) ایک مثالی تبدیلی کی نمائندگی کرتے ہیں، جو ان دو شعبوں کو ملا کر ایسے AI ماڈلز بناتے ہیں جو دنیا کو زیادہ جامع، انسانی طرح سے سمجھ اور استدلال کر سکتے ہیں۔

ایک VLM ایک ملٹی موڈل AI ماڈل ہے جو تصاویر (یا ویڈیو) اور متن دونوں سے بیک وقت معلومات پر کارروائی کر سکتا ہے۔ یہ اسے ایسے کام انجام دینے کی اجازت دیتا ہے جو ایک یونیموڈل ماڈل کے لیے ناممکن ہیں۔

**VLMs کی بنیادی صلاحیتیں:**

*   **بصری سوالات کے جوابات (VQA):** ایک تصویر اور قدرتی زبان کا سوال (جیسے، "میز پر کتنے سیب ہیں؟") دیا گیا، ماڈل ایک متنی جواب فراہم کرتا ہے۔
*   **امیج کیپشننگ:** ماڈل ایک تصویر کی ایک مختصر، انسانی جیسی تفصیل تیار کرتا ہے۔ (جیسے، "ایک بھورا کتا ایک گھاس والے پارک میں سرخ فریزبی پکڑ رہا ہے۔")۔
*   **گراؤنڈڈ لینگویج انڈرسٹینڈنگ (بصری گراؤنڈنگ):** ماڈل ایک متن میں الفاظ یا فقروں کو کسی تصویر کے اندر مخصوص اشیاء یا علاقوں سے جوڑتا ہے۔ اگر آپ کہتے ہیں، "بائیں طرف کی بوتل،" تو ماڈل شناخت کر سکتا ہے کہ کون سے پکسلز اس مخصوص بوتل سے مطابقت رکھتے ہیں۔ یہ روبوٹکس کے لیے بہت اہم ہے۔
*   **ٹیکسٹ ٹو امیج ریٹریول:** ایک متنی تفصیل دی گئی، ماڈل تصاویر کے ڈیٹا بیس میں تلاش کر سکتا ہے اور ان کو تلاش کر سکتا ہے جو تفصیل سے بہترین مماثل ہوں۔

ایک روبوٹ کے لیے، ان صلاحیتوں کا مطلب ہے کہ وہ ان ہدایات کو سمجھ سکتا ہے جو اس کے ماحول میں موجود اشیاء کا حوالہ دیتی ہیں، جیسے "نیلا کپ اٹھاؤ" بجائے اس کے کہ عین مطابق نقاط کی ضرورت ہو۔

***
*خاکہ کے لیے پلیس ہولڈر: "VLM فن تعمیر۔" اس خاکہ کو دو اہم شاخیں دکھانی چاہئیں:
1.  **وژن انکوڈر:** ایک ان پٹ تصویر کو وژن بیک بون (جیسے، ایک وژن ٹرانسفارمر - ViT) میں فیڈ کیا جاتا ہے جو تصویری خصوصیات (ایمبیڈنگز) کا ایک سیٹ آؤٹ پٹ کرتا ہے۔
2.  **لینگویج انکوڈر:** ایک ان پٹ ٹیکسٹ پرامپٹ کو لینگویج ماڈل (جیسے، ایک ٹرانسفارمر ڈیکوڈر جیسے GPT) میں فیڈ کیا جاتا ہے جو ٹیکسٹ ایمبیڈنگز کو آؤٹ پٹ کرتا ہے۔
3.  **فیوژن لیئر:** پھر ان دو ایمبیڈنگز کے سیٹ کو "کراس اٹینشن" میکانزم کے ذریعے ایک ساتھ فیوز کیا جاتا ہے، جس سے ماڈل کو بصری تصورات اور الفاظ کے درمیان تعلقات سیکھنے کی اجازت ملتی ہے۔
4.  **آؤٹ پٹ ہیڈ:** پھر فیوز شدہ نمائندگی کو ایک حتمی پرت میں منتقل کیا جاتا ہے جو مطلوبہ آؤٹ پٹ تیار کرتا ہے (جیسے، ایک جواب، ایک کیپشن، یا ایک باؤنڈنگ باکس)۔
***

## 1.2 تفہیم کا انجن: بڑے لینگویج ماڈلز (LLMs)

VLMs میں حالیہ، ڈرامائی بہتری بڑی حد تک بڑے لینگویج ماڈلز (LLMs) کی طاقت کی بدولت ہے۔ LLMs نیورل نیٹ ورکس ہیں، جو عام طور پر ٹرانسفارمر فن تعمیر پر مبنی ہوتے ہیں، جنہیں واقعی بڑے پیمانے پر ٹیکسٹ ڈیٹا پر تربیت دی گئی ہے۔

**LLMs نے گیم کیسے بدلا:**

1.  **ابھرتی ہوئی صلاحیتیں:** جب بڑے پیمانے پر تربیت دی جاتی ہے، تو LLMs "ابھرتی ہوئی صلاحیتیں" تیار کرتے ہیں — ایسی مہارتیں جن کے لیے انہیں واضح طور پر پروگرام نہیں کیا گیا تھا۔ ان میں عقل عام، بنیادی ریاضی، اور زبان میں سیاق و سباق اور باریکی کو سمجھنے کی صلاحیت شامل ہے۔
2.  **ٹرانسفارمر فن تعمیر:** زیادہ تر جدید LLMs کے پیچھے بنیادی اختراع ٹرانسفارمر ہے، جو "سیلف اٹینشن" نامی ایک میکانزم استعمال کرتا ہے۔ سیلف اٹینشن ماڈل کو ان پٹ متن میں مختلف الفاظ کی اہمیت کو ایک دوسرے کے نسبت تولنے کی اجازت دیتا ہے، جس سے اسے گرامر اور نحو کی ایک جدید تفہیم ملتی ہے۔
3.  **پری ٹریننگ اور فائن ٹیوننگ:**
    *   **پری ٹریننگ:** ایک LLM کو پہلے متن کے ایک وسیع، عمومی کارپس (جیسے انٹرنیٹ کا ایک اہم حصہ) پر "پری ٹرینڈ" کیا جاتا ہے۔ مقصد سادہ ہے: ایک جملے میں اگلے لفظ کی پیشن گوئی کریں۔ اربوں بار ایسا کرنے سے، ماڈل زبان اور دنیا کے بارے میں ناقابل یقین حد تک سیکھتا ہے۔
    *   **فائن ٹیوننگ:** پری ٹریننگ کے بعد، عمومی ماڈل کو کسی مخصوص کام کے لیے ایک چھوٹے، کیوریٹڈ ڈیٹاسیٹ پر "فائن ٹیون" کیا جا سکتا ہے۔ یہ ماڈل کے عمومی علم کو ایک خصوصی ڈومین، جیسے طبی متن کا تجزیہ یا، ہمارے معاملے میں، روبوٹکس کمانڈز کے مطابق ڈھالتا ہے۔

جب یہ طاقتور زبان کی تفہیم کو وژن سسٹم کے ساتھ ملایا جاتا ہے، تو نتیجہ خیز VLM متن سے سیکھے گئے بھرپور، تجریدی علم کو اپنے سینسرز سے ٹھوس، بصری معلومات سے جوڑ سکتا ہے۔

## 1.3 OpenAI API: طاقتور AI ماڈلز تک آپ کا گیٹ وے

اس کورس کے لیے، ہم OpenAI کے پہلے سے تربیت یافتہ ماڈلز کا فائدہ اٹھائیں گے، جو ایک سادہ اور اچھی طرح سے دستاویزی API کے ذریعے قابل رسائی ہیں۔ یہ ہمیں दिग्गजों کے کندھوں پر کھڑے ہونے اور اپنے پروجیکٹس میں جدید ترین AI کو مربوط کرنے کی اجازت دیتا ہے بغیر ان بڑے ماڈلز کو خود تربیت دینے کی ضرورت کے۔

*   **GPT (جنریٹو پری ٹرینڈ ٹرانسفارمر):** LLMs کا ایک خاندان۔ ہم بنیادی طور پر چیٹ پر مبنی ماڈلز (جیسے `gpt-3.5-turbo` اور `gpt-4`) استعمال کریں گے جو مکالمے اور ہدایات پر عمل کرنے کے لیے موزوں ہیں۔ یہ ماڈلز ہمارے روبوٹ کا "دماغ" ہوں گے، جو اسے استدلال اور منصوبہ بندی میں مدد دیں گے۔
*   **Whisper:** ایک جدید ترین خودکار اسپیچ ریکگنیشن (ASR) ماڈل۔ اسے کثیر لسانی آڈیو کے ایک بہت بڑے ڈیٹاسیٹ پر تربیت دی گئی ہے اور یہ بولی جانے والی زبان کو قابل ذکر درستگی کے ساتھ متن میں نقل کر سکتا ہے، یہاں تک کہ شور والے حالات میں بھی۔ Whisper ہمارے روبوٹ کے "کان" ہوں گے۔

**اپنا API کلید حاصل کرنا:**

1.  **ایک OpenAI اکاؤنٹ بنائیں:** [OpenAI پلیٹ فارم ویب سائٹ](https://platform.openai.com/) پر جائیں اور سائن اپ کریں۔
2.  **بلنگ سیٹ اپ کریں:** API استعمال کرنے کے لیے آپ کو اپنے اکاؤنٹ میں ادائیگی کا طریقہ شامل کرنے کی ضرورت ہوگی۔ OpenAI نئے صارفین کے لیے تھوڑی مقدار میں مفت کریڈٹ فراہم کرتا ہے، لیکن اس سے آگے کا استعمال ادا شدہ ہے۔
3.  **ایک API کلید بنائیں:** اپنے اکاؤنٹ کے ڈیش بورڈ میں "API کلیدیں" سیکشن پر جائیں۔ "نئی خفیہ کلید بنائیں" پر کلک کریں۔ **اہم:** اس کلید کو کاپی کریں اور اسے کسی محفوظ جگہ پر محفوظ کریں۔ آپ اسے دوبارہ نہیں دیکھ پائیں گے۔ **اپنی API کلید کو کبھی بھی عوامی کوڈ ریپوزٹری میں کمٹ نہ کریں۔**

**اپنا ماحول ترتیب دینا:**

```bash
# OpenAI پائتھن لائبریری انسٹال کریں
pip install openai

# اپنی API کلید کو ماحولیاتی متغیر کے طور پر سیٹ کرنے کی انتہائی سفارش کی جاتی ہے
# اس لائن کو اپنی ~/.bashrc یا ~/.zshrc فائل میں شامل کریں
export OPENAI_API_KEY='YOUR_API_KEY_HERE'

# پھر، تبدیلیوں کو لاگو کرنے کے لیے فائل کو سورس کریں (جیسے، source ~/.bashrc)
```

**مثال: GPT-4 پر ایک مضبوط API کال**

```python
import os
import openai

# لائبریری خود بخود OPENAI_API_KEY ماحولیاتی متغیر اٹھا لے گی
# openai.api_key = os.getenv("OPENAI_API_KEY") # یہ اب واضح طور پر کیا جاتا ہے

try:
    response = openai.chat.completions.create(
        model="gpt-4",  # یا "gpt-3.5-turbo"
        messages=[
            {"role": "system", "content": "آپ ایک مددگار اسسٹنٹ ہیں۔"},
            {"role": "user", "content": "آئزک نیوٹن اور گوٹ فرائیڈ لیبنز کے درمیان کیا تعلق ہے؟"}
        ],
        max_tokens=150
    )
    
    # جوابی مواد کو صحیح طریقے سے حاصل کرنا
    message_content = response.choices[0].message.content
    print(message_content)

except openai.APIError as e:
    print(f"ایک OpenAI API کی خرابی واقع ہوئی: {e}")
except Exception as e:
    print(f"ایک غیر متوقع خرابی واقع ہوئی: {e}")

```
*یہ اسکرپٹ OpenAI کے چیٹ ماڈلز کے ساتھ تعامل کا جدید، تجویز کردہ طریقہ دکھاتا ہے، بشمول بنیادی خرابی سے نمٹنا۔*

## 1.4 VLM انضمام کے لیے ایک ROS 2 برج

ان کلاؤڈ پر مبنی AI ماڈلز کو اپنے مقامی روبوٹکس سسٹم میں صاف طور پر مربوط کرنے کے لیے، ہم ایک وقف شدہ ROS 2 نوڈ بنائیں گے۔ یہ نوڈ ایک سروس فراہم کنندہ کے طور پر کام کرے گا، دوسرے ROS 2 نوڈس سے درخواستیں قبول کرے گا، OpenAI API کو کال کرے گا، اور نتیجہ واپس کرے گا۔ یہ تعمیراتی نمونہ ہر نوڈ کے اپنے API کالز کرنے سے کہیں زیادہ صاف ہے۔

**ROS 2 پیکیج بنانا:**

```bash
# اپنے ROS 2 ورک اسپیس کے src ڈائرکٹری پر جائیں
cd ~/ros2_ws/src

# ہماری VLM سروسز کے لیے ایک نیا پیکیج بنائیں
ros2 pkg create --build-type ament_python vlm_services --dependencies rclpy std_msgs
```

**ایک بنیادی ROS 2 سروس نوڈ بنانا:**

`vlm_services/vlm_services` ڈائرکٹری میں ایک نئی پائتھن فائل `openai_service_node.py` بنائیں۔ ہم ایک سادہ سروس کے ساتھ شروع کریں گے جو ایک سٹرنگ لیتی ہے اور ایک سٹرنگ واپس کرتی ہے۔

```python
# سب سے پہلے، آئیے اپنے پیکیج میں ایک کسٹم سروس کی وضاحت کریں۔
# "vlm_services" پیکیج کے اندر ایک نئی "srv" ڈائرکٹری میں "StringToString.srv" نامی ایک فائل بنائیں
# جس میں درج ذیل مواد ہو:
#
# string input
# ---
# string output
#
# پھر، سروس بنانے کے لیے package.xml اور CMakeLists.txt میں ترمیم کریں۔

# پائتھن نوڈ (openai_service_node.py):
import rclpy
from rclpy.node import Node
# ہم بعد میں یہ کسٹم سروس بنائیں گے
# from vlm_services.srv import StringToString 

class OpenAIServiceNode(Node):
    def __init__(self):
        super().__init__('openai_service_node')
        # ہم سروس کی وضاحت ہونے پر اسے غیر تبصرہ کریں گے
        # self.srv = self.create_service(StringToString, 'openai_service', self.service_callback)
        self.get_logger().info('OpenAI سروس نوڈ شروع ہو گیا ہے۔')

    def service_callback(self, request, response):
        self.get_logger().info(f'درخواست موصول ہوئی: {request.input}')
        
        # یہ وہ جگہ ہے جہاں ہم OpenAI API کو کال کریں گے
        # ابھی کے لیے، ہم صرف ان پٹ کو بازگشت کریں گے
        
        response.output = "کے لیے OpenAI جواب: " + request.input
        return response

def main(args=None):
    rclpy.init(args=args)
    openai_service_node = OpenAIServiceNode()
    rclpy.spin(openai_service_node)
    openai_service_node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```
*یہ کوڈ ایک API سروس نوڈ کے لیے ایک مضبوط نقطہ آغاز فراہم کرتا ہے۔ اگلے ابواب میں، ہم سروس کی تعریف اور API کال منطق کو بنائیں گے۔*

## 1.5 خلاصہ

اس باب میں، آپ نے وژن-لینگویج ماڈلز کے پیچھے کے تصورات میں گہری ڈائیونگ کی ہے۔ آپ نے سیکھا کہ وہ کس طرح کمپیوٹر وژن اور NLP کا ایک فیوژن ہیں، جو بڑے لینگویج ماڈلز کی طاقت سے چلتا ہے۔ آپ نے اپنے ڈیولپر ماحول کو جدید ترین OpenAI API تک رسائی حاصل کرنے کے لیے بھی ترتیب دیا ہے اور ان طاقتور کلاؤڈ سروسز کو اپنے ROS 2 پروجیکٹس میں مربوط کرنے کے لیے تعمیراتی بنیاد رکھی ہے۔ اگلے باب میں، ہم اس بنیاد پر ایک آواز سے کنٹرول شدہ روبوٹکس سسٹم بنانے کے لیے Whisper API کا استعمال کریں گے۔
